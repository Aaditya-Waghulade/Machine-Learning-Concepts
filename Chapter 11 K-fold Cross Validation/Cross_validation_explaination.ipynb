{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9a4b57-e37a-4811-8ecf-06c5b0972130",
   "metadata": {},
   "source": [
    "# Defination of Cross Validation\n",
    "It is the processure which says that which one of the Algorithm we should use for Data Modeling. \n",
    "It Validate the and evaluate that which algorithm's performance will be good fit for the particular Problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2fb37-ce1b-4478-bc99-9c98d940a52b",
   "metadata": {},
   "source": [
    "# How does k-Fold validation works?\n",
    "It is like train test split but this works very purely\n",
    "1) First example: - we will devide our 100 samples into 5 different folds where 1 fold = 20 samples then we will notedown each folds scores with the help of iterations. Any one fold will be for test and rest of the 4 will be trained model.\n",
    "2) Then we take all scores of 5 Tested folds and we will consider the average Score of all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cea266-d5dd-47d8-9dc8-67a20e2357c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "digits = load_digits()\n",
    "logic_model = LogisticRegression()\n",
    "tree_model = RandomForestClassifier()\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "116e9d91-a695-4b33-99e6-b6d058fce295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First lets split digits datasets into train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(digits.data,digits.target , test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b263e651-f563-402a-9091-61b74e043548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will check our all Algorithms one by one\n",
    "#1) Logistic Regression\n",
    "logic_model.fit(X_train,y_train)\n",
    "logic_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94c8df98-f488-47b7-a66a-99115634c6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2) Random Forest Classifier\n",
    "tree_model.fit(X_train,y_train)\n",
    "tree_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "730e6e87-dcf0-422e-94d1-5ec3ca6942ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3) Support Vector Machine\n",
    "svm.fit(X_train,y_train)\n",
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb2064ab-8459-43dd-9d59-671642dcf8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actually we made a function for to calculate score in with different Algorithms\n",
    "def get_score(model,X_train,X_test,y_train,y_test):#Taking input as model and train_test_split\n",
    "    model.fit(X_train,y_train)#Fit the model\n",
    "    return model.score(X_test,y_test)#Returning the score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f91b971-0670-4660-a02a-7902fe5860bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score( tree_model,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57f081c8-6105-4cda-848e-bf0dbfd2b034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851851851851852"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score( svm,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0ad391d-4763-48dc-a013-2bab0bff05ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9740740740740741"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score( LogisticRegression(),X_train,X_test,y_train,y_test)#Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e404ec-8e04-4536-8ae6-4c42cb8a26c7",
   "metadata": {},
   "source": [
    "# Hence we tried All the Algorithms one by one and not down the scores but lets try K-fold Technique now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5bac4f5-54fe-485a-811b-4731d5148113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 3)#You have to specify how many folds do you want to make using \"n_splits\"\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da5b9952-4268-4eb3-b3c3-6ec7ef7158dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6 7 8 9] [0 1 2 3]\n",
      "[0 1 2 3 7 8 9] [4 5 6]\n",
      "[0 1 2 3 4 5 6] [7 8 9]\n"
     ]
    }
   ],
   "source": [
    "#Implimentation of kf.split\n",
    "#Here we have n_splits = 3 so it divided the fold after every three elements.\n",
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9,0]):\n",
    "    print(train_index,test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd3810-06eb-45df-a695-c09514ebfb58",
   "metadata": {},
   "source": [
    "# Now this function is only for Explaining you that how you can select a model for your problem that which model will be best suitable for your problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "72754458-59fc-4abe-b080-4fd9cb5e18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold#Stratified KFold is little better than KFold and its Accuracy is also good than Normal KFold\n",
    "folds = StratifiedKFold(n_splits = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9322d6c6-67f4-49e5-add2-3d3fbfcf76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "score_logistic=[]#Dummy variable for storing the scores of there particular Algorithm\n",
    "score_svm=[]\n",
    "score_tree=[ ]\n",
    "#Function which will train_test_split the data and target one by one and will store its Scores in the dummy variables\n",
    "for train_index , test_index in kf.split(digits.data):#Giving input an independent variable such as 'digits.data'\n",
    "    #Now this below code is normal syntax of X_train and y_train but it is now 3D array so you have to repeat 'digits.data' 2 times and 'digits.target' 2 times\n",
    "    X_train,X_test,y_train,y_test = digits.data[train_index] , digits.data[test_index], \\\n",
    "                                    digits.target[train_index],digits.target[test_index]\n",
    "    score_logistic.append(get_score( tree_model,X_train,X_test,y_train,y_test))\n",
    "    score_svm.append(get_score( logic_model,X_train,X_test,y_train,y_test))\n",
    "    score_tree.append(get_score( svm,X_train,X_test,y_train,y_test))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6074faa0-2e01-4c90-af0e-16f49d77abc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9365609348914858, 0.9616026711185309, 0.9315525876460768]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "42f35fb7-4b20-4d11-bc57-7db6639860ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9232053422370617, 0.9415692821368948, 0.9148580968280468]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ccb632df-6009-4ffd-a29b-4d227dc23a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9666110183639399, 0.9816360601001669, 0.9549248747913188]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50570ad-1429-4947-a5d4-c8222eaedab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now taking Average of that 3 scores and can say that which model will be best fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3770f5-8ae1-48a6-a768-940fec4b1d7c",
   "metadata": {},
   "source": [
    "# For taking decision that which algorithm should we use for our particular problem we actually uses Cross Validation but Sci-kit learn already have  the premade function which says the score of this functions and then we will dicide which to use\n",
    "1) For this we will first import cross_val_score from skitiLearn Library from model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9ed3d87d-4c68-42c4-8201-058c6c6aa8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9137650882079852"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logic_model,digits.data,digits.target).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "48803ba7-b4ab-4668-9ff9-febb4b72f0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981878675332714"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators = 10),digits.data,digits.target).mean()#(first position=Algorithm,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5195437d-a879-416c-8b0e-d3052fd87b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632838130609718"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm,digits.data,digits.target).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3ade3-b020-4964-ab37-89dd67a78066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e243c-82bd-4d48-85d2-99f3457b1bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
